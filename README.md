# Code of Biterm Topic Model
This is a python extension based on the original code


Biterm Topic Model (BTM) is a word co-occurrence based topic model that learns topics by modeling word-word co-occurrences patterns (e.g., biterms).
(In constrast, LDA and PLSA are word-document co-occurrence topic models, since they model word-document co-occurrences.)

A biterm consists of two words co-occurring in the same context, for example, in the same short text window. Unlike LDA models the word occurrences, BTM models the biterm occurrences in a corpus. In generation procedure, a biterm is generated by drawn two words independently from a same topic. In other words, the distribution of a biterm b=(wi,wj) is defined as:

       P(b) = \sum_k{P(wi|z)*P(wj|z)*P(z)}.

With Gibbs sampling algorithm, we can learn topics by estimate P(w|k) and P(z).

More detail can be referred to the following paper:

> Xiaohui Yan, Jiafeng Guo, Yanyan Lan, Xueqi Cheng. A Biterm Topic Model For Short Text. WWW2013.

## Usage ##
```bash
cd $project
pip install .
```
The setup.py will compile the extension


It is possible to fit the whole data usen the fit method using `n_iters` iterations.
```python
import btm
number_of_topics = 2
alpha = 50/2
beta = 0.0005
n_iters = 50000
background_topic = True
show_progressbar = True
btm_model = btm.Model(number_of_topics, alpha, beta, n_iters, background_topic, show_progressbar)
btm_model.fit(["sentence 1", "sentence 2", "sentence 2"])
pz = btm_model.get_pz()
pw_z = btm_model.get_pw_z( )
vocabulary = btm_model.vocabulary()
b = btm_model.predict(["ANother sentence"], "sum_b")
```
or it is possible to ignore `n_iters` and fit the model manually using the `fit_step` method. It is
necessary, nevertheless, to call the `initialize` method with the corpus.
```python
import btm
number_of_topics = 2
alpha = 50/2
beta = 0.0005
n_iters = 0
background_topic = True
show_progressbar = True
btm_model = btm.Model(number_of_topics, alpha, beta, n_iters, background_topic, show_progressbar)
btm_model.initialize(["sentence 1", "sentence 2", "sentence 2"])
for j in range(500):
    btm_model.fit_step()
```
## Related codes ##
- [Online BTM](https://github.com/xiaohuiyan/OnlineBTM)
- [Bursty BTM](https://github.com/xiaohuiyan/BurstyBTM)

## History ##
- 2015-01-12, v0.5, improve the usability of the code
- 2012-09-25, v0.1

If there is any question, feel free to contact: [Xiaohui Yan](http://xiaohuiyan.github.io "Xiaohui Yan")(xhcloud@gmail.com).

